{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search:\n",
    "# The majority of machine learning models contain parameters that can be adjusted to vary how \n",
    "# the model learns. For example, the logistic regression model, from sklearn, has a parameter C \n",
    "# that controls regularization,which affects the complexity of the model.\n",
    "\n",
    "# How do we pick the best value for C? The best value is dependent on the data used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does it work?\n",
    "# One method is to try out different values and then pick the value that gives the best score. \n",
    "# This technique is known as a \"grid search\". If we had to select the values for two or more parameters, \n",
    "# we would evaluate all combinations of the sets of values thus forming a grid of values.\n",
    "\n",
    "# Before we get into the example it is good to know what the parameter we are changing does. \n",
    "# Higher values of C tell the model, the training data resembles real world information, \n",
    "# place a greater weight on the training data. While lower values of C do the opposite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Default Parameters:\n",
    "# First let's see what kind of results we can generate without a grid search using only \n",
    "# the base parameters.\n",
    "\n",
    "# To get started we must first load in the dataset we will be working with.\n",
    "\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Next in order to create the model we must have a set of independent variables X and a \n",
    "# dependant variable y.\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "# Now we will load the logistic model for classifying the iris flowers.\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Creating the model, setting max_iter to a higher value to ensure that the model finds a result.\n",
    "\n",
    "# Keep in mind the default value for C in a logistic regression model is 1, we will compare this later.\n",
    "\n",
    "# In the example below, we look at the iris data set and try to train a model with varying \n",
    "# values for C in logistic regression.\n",
    "\n",
    "logit = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "# After we create the model, we must fit the model to the data.\n",
    "\n",
    "print(logit.fit(X,y))\n",
    "\n",
    "# To evaluate the model we run the score method.\n",
    "\n",
    "print(logit.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=10000)\n",
      "0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "logit = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "print(logit.fit(X,y))\n",
    "\n",
    "print(logit.score(X,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With the default setting of C = 1, we achieved a score of 0.973.\n",
    "\n",
    "# Let's see if we can do any better by implementing a grid search with difference values of 0.973."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 0.9666666666666667, 0.9733333333333334, 0.9733333333333334, 0.98, 0.98, 0.9866666666666667, 0.9866666666666667]\n"
     ]
    }
   ],
   "source": [
    "# Implementing Grid Search:\n",
    "# We will follow the same steps of before except this time we will set a range of values for C.\n",
    "\n",
    "# Knowing which values to set for the searched parameters will take a combination of domain \n",
    "# knowledge and practice.\n",
    "\n",
    "# Since the default value for C is 1, we will set a range of values surrounding it.\n",
    "\n",
    "C = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "\n",
    "# Next we will create a for loop to change out the values of C and evaluate the model with each change.\n",
    "\n",
    "# First we will create an empty list to store the score within.\n",
    "\n",
    "scores = []\n",
    "\n",
    "# To change the values of C we must loop over the range of values and update the parameter each time.\n",
    "\n",
    "for choice in C:\n",
    "  logit.set_params(C=choice)\n",
    "  logit.fit(X, y)\n",
    "  scores.append(logit.score(X, y))\n",
    "\n",
    "# With the scores stored in a list, we can evaluate what the best choice of C is.\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9666666666666667, 0.9666666666666667, 0.9733333333333334, 0.9733333333333334, 0.98, 0.98, 0.9866666666666667, 0.9866666666666667]\n"
     ]
    }
   ],
   "source": [
    "# Example:\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "logit = LogisticRegression(max_iter = 10000)\n",
    "\n",
    "C = [0.25, 0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]\n",
    "\n",
    "scores = []\n",
    "\n",
    "for choice in C:\n",
    "  logit.set_params(C=choice)\n",
    "  logit.fit(X, y)\n",
    "  scores.append(logit.score(X, y))\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results Explained:\n",
    "\n",
    "# We can see that the lower values of C performed worse than the base parameter of 1. However, \n",
    "# as we increased the value of C to 1.75 the model experienced increased accuracy.\n",
    "\n",
    "# It seems that increasing C beyond this amount does not help increase model accuracy.\n",
    "\n",
    "# Note on Best Practices:\n",
    "# We scored our logistic regression model by using the same data that was used to train it. \n",
    "# If the model corresponds too closely to that data, it may not be great at predicting unseen data. \n",
    "# This statistical error is known as over fitting.\n",
    "\n",
    "# To avoid being misled by the scores on the training data, we can put aside a portion of our data\n",
    "# and use it specifically for the purpose of testing the model. Refer to the lecture on train/test\n",
    "# splitting to avoid being misled and overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
